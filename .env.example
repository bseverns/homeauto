# Copy this file to .env and then edit like the unapologetic home lab conductor you are.
# Any value tagged with "tune me" deserves a real value in your stack.

# System basics
TZ=America/Los_Angeles        # tune me: pick your actual timezone from https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
CORE_HOSTNAME=core            # tune me: hostname for the CORE role
CORE_IP=192.168.50.50          # tune me: static IPv4 for CORE on your LAN
ORIN_HOSTNAME=orin-core        # legacy alias for CORE (optional, should match CORE_HOSTNAME)
ORIN_IP=192.168.50.50          # legacy alias for CORE (optional, should match CORE_IP)
ROUTER_LAN=192.168.50.0/24     # tune me: your LAN subnet in CIDR form
ROUTER_LAN_GATEWAY=192.168.50.1 # tune me: default gateway handed out by DHCP
ROUTER_DNS_V4=192.168.50.50    # tune me: IPv4 DNS endpoint (Pi-hole on the Orin in the map)
ROUTER_DNS_V6=fd00::50         # tune me: IPv6 DNS endpoint (optional — blank if unused)
ENABLE_IPV6=true               # flip to false if you’re skipping IPv6 for now

# Role split (optional)
AUDIO_HOST=audio-node          # optional: hostname for audio slice if it runs elsewhere
AUDIO_IP=192.168.50.61         # optional: static IPv4 for audio host
ASSISTANT_HOST=assistant-node  # optional: hostname for assistant/experiments node
ASSISTANT_API_URL=http://192.168.50.62:7070 # optional: API endpoint for assistant queries

# Audio fabric
MOPIDY_FIFO=/tmp/snapfifo_music
LIBRESPOT_FIFO=/tmp/snapfifo_spotify
VINYL_ALSA_DEV=hw:1,0          # tune me: ALSA capture device for your vinyl input
SNAPWEB_PORT=1780

# Home Assistant & friends
HA_URL=http://homeassistant.local:8123 # tune me: URL Home Assistant listens on
PIHOLE_PASSWORD=change-me       # tune me: set a proper Pi-hole UI password before going live

# Remote access
TAILSCALE_AUTHKEY=tskey-please-set # tune me: issue a reusable auth key from the Tailscale admin console

# Local assistant stack (LLM + RAG)
ASSISTANT_MODEL_PATH=/models/llama3-8b-q4_k_m.gguf # tune me: GGUF model path inside the llama.cpp container
ASSISTANT_GPU_LAYERS=32                             # tune me: GPU layers for llama.cpp (Jetson sweet spot varies)
ASSISTANT_CTX_SIZE=4096                             # tune me: context size (bigger = slower + more VRAM)
ASSISTANT_COLLECTION=homeauto-assistant             # tune me: Qdrant collection name
ASSISTANT_COLLECTION_TAG=homeauto                   # tune me: tag to filter queries by source stack
ASSISTANT_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
ASSISTANT_DATA_ROOTS=                               # optional: comma-separated extra paths to ingest

# Keep the FIFOs under version control if you pre-create them:
# data/snapcast/fifo/music -> matches MOPIDY_FIFO
# data/snapcast/fifo/spotify -> matches LIBRESPOT_FIFO
